{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank to Sazuma for baseline https://www.kaggle.com/shoheiazuma/tweet-sentiment-roberta-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1Oqu4m4BFcu",
    "outputId": "3a6fe18d-ba68-4f7c-d9d4-257129fa4ebf"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFT2w2E8rkmL"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULBA-PclrkmM",
    "outputId": "3937e4aa-b1d7-4fec-e60d-cae33f7e0301"
   },
   "outputs": [],
   "source": [
    "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n",
    "\n",
    "#!export XLA_USE_BF16=1\n",
    "!pip install tokenizers\n",
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gegjmLuZrkmZ",
    "outputId": "e1188698-dd79-4c2f-f941-990599c59066"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import random\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tokenizers\n",
    "\n",
    "# import torch_xla.core.xla_model as xm\n",
    "# import torch_xla.distributed.parallel_loader as pl\n",
    "# import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import lr_scheduler\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import RobertaModel, RobertaConfig\n",
    "from tqdm.autonotebook import tqdm\n",
    "#import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDgchGhncN9U"
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiV5dABS3Xlz"
   },
   "outputs": [],
   "source": [
    "# Datetime variables\n",
    "TIMESTAMP = datetime.now(tz=pytz.timezone(\"Europe/Moscow\")).strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "\n",
    "# Without train\n",
    "IS_MISS_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-XNw5nq4Kjp",
    "outputId": "525397cb-acc5-46fb-c98b-4b41265d711e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    COLAB_USE = True\n",
    "except:\n",
    "    COLAB_USE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_PdxihhvXXf"
   },
   "outputs": [],
   "source": [
    "if COLAB_USE:\n",
    "    INPUT = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/input/'\n",
    "      \n",
    "    OUTPUT = f'/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/output/{TIMESTAMP}/'\n",
    "    os.makedirs(OUTPUT, exist_ok = False)\n",
    "    ARCHIVE_FILE = OUTPUT + 'models.zip'\n",
    "\n",
    "    MODELS = 'models/'\n",
    "    # MODELS = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/models/'\n",
    "    if not IS_MISS_TRAIN and os.path.exists(MODELS):\n",
    "        shutil.rmtree(MODELS)\n",
    "    #os.makedirs(MODELS, exist_ok = False)\n",
    "    for epoch in (2,3,4,5):\n",
    "        os.makedirs(f'{MODELS}e{epoch}')\n",
    "else:\n",
    "    INPUT = '../input/'\n",
    "    MODELS = os.path.join(INPUT,'20200615t234256-e4/')\n",
    "    #MODELS = os.path.join(INPUT,'20200615t234256-e-best/')\n",
    "    OUTPUT = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {MODELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ea_JNj0rkmd",
    "outputId": "e3bb5849-7596-44ae-ba10-6dc6bdbdd84d"
   },
   "outputs": [],
   "source": [
    "# Paths variables\n",
    "COLAB = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/'\n",
    "VOCAB_RB = os.path.join(INPUT,'roberta-base/vocab.json')\n",
    "MERGES_RB = os.path.join(INPUT,'roberta-base/merges.txt')\n",
    "CONFIG_RB = os.path.join(INPUT,'roberta-base/config.json')\n",
    "MODEL_RB = os.path.join(INPUT,'roberta-base/pytorch_model.bin')\n",
    "TRAIN = os.path.join(INPUT,'tweet-sentiment-extraction/train.csv')\n",
    "TEST = os.path.join(INPUT,'tweet-sentiment-extraction/test.csv')\n",
    "SAMPLE_SUBM = os.path.join(INPUT,'tweet-sentiment-extraction/sample_submission.csv')\n",
    "\n",
    "#Check gpu\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BjxMJYfqKwh"
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlKdFB6Q5dOm"
   },
   "outputs": [],
   "source": [
    "def ps(*args):\n",
    "    print(*args)\n",
    "    with open(os.path.join(OUTPUT,'output.txt'), 'a') as f:\n",
    "        print(*args, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JN2ZozwXrkmj"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "#device = torch.device('cpu')\n",
    "#fold = 0\n",
    "#device = xm.xla_device(fold + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJjMOh4grkmn"
   },
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "hRJQuBF3rkmn"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYsn6nWmrkmr"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFhfCy5Mrkms"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, max_len=96):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.labeled = 'selected_text' in df\n",
    "        self.tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "            vocab_file=VOCAB_RB, \n",
    "            merges_file=MERGES_RB, \n",
    "            lowercase=True,\n",
    "            add_prefix_space=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {}\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        ids, masks, tweet, offsets = self.get_input_data(row)\n",
    "        data['ids'] = ids\n",
    "        data['masks'] = masks\n",
    "        data['tweet'] = tweet\n",
    "        data['offsets'] = offsets\n",
    "        \n",
    "        if self.labeled:\n",
    "            start_idx, end_idx = self.get_target_idx(row, tweet, offsets)\n",
    "            data['start_idx'] = start_idx\n",
    "            data['end_idx'] = end_idx\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_input_data(self, row):\n",
    "        tweet = \" \" + \" \".join(row.text.lower().split())\n",
    "        encoding = self.tokenizer.encode(tweet)\n",
    "        sentiment_id = self.tokenizer.encode(row.sentiment).ids\n",
    "        ids = [0] + sentiment_id + [2, 2] + encoding.ids + [2]\n",
    "        offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n",
    "                \n",
    "        pad_len = self.max_len - len(ids)\n",
    "        if pad_len > 0:\n",
    "            ids += [1] * pad_len\n",
    "            offsets += [(0, 0)] * pad_len\n",
    "        \n",
    "        ids = torch.tensor(ids)\n",
    "        masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n",
    "        offsets = torch.tensor(offsets)\n",
    "        \n",
    "        return ids, masks, tweet, offsets\n",
    "        \n",
    "    def get_target_idx(self, row, tweet, offsets):\n",
    "        selected_text = \" \" +  \" \".join(row.selected_text.lower().split())\n",
    "\n",
    "        len_st = len(selected_text) - 1\n",
    "        idx0 = None\n",
    "        idx1 = None\n",
    "\n",
    "        for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "            if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                break\n",
    "\n",
    "        char_targets = [0] * len(tweet)\n",
    "        if idx0 != None and idx1 != None:\n",
    "            for ct in range(idx0, idx1 + 1):\n",
    "                char_targets[ct] = 1\n",
    "\n",
    "        target_idx = []\n",
    "        for j, (offset1, offset2) in enumerate(offsets):\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                target_idx.append(j)\n",
    "\n",
    "        start_idx = target_idx[0]\n",
    "        end_idx = target_idx[-1]\n",
    "        \n",
    "        return start_idx, end_idx\n",
    "        \n",
    "def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(train_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=2,\n",
    "        drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(val_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)\n",
    "\n",
    "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    return dataloaders_dict\n",
    "\n",
    "def get_test_loader(df, batch_size=32):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QuttLhyrkmv"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOlWWfKjrkmy"
   },
   "outputs": [],
   "source": [
    "class TweetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TweetModel, self).__init__()\n",
    "        \n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            CONFIG_RB, output_hidden_states=True)    \n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            MODEL_RB, config=config)\n",
    "        self.dropout = nn.Dropout(0.9)\n",
    "        self.fc = nn.Linear(config.hidden_size, 2)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, _, hs = self.roberta(input_ids, attention_mask)\n",
    "         \n",
    "        #x = torch.stack([hs[-1], hs[-2], hs[-3]])\n",
    "        x = torch.stack([hs[-1], hs[-2]])\n",
    "        x = torch.mean(x, 0)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        start_logits, end_logits = x.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "                \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od1c1htarkm2"
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_zP0Smkrkm2"
   },
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    start_loss = ce_loss(start_logits, start_positions)\n",
    "    end_loss = ce_loss(end_logits, end_positions)    \n",
    "    total_loss = start_loss + end_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOO4Sp7-rkm5"
   },
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkBtrAaAxfTd"
   },
   "outputs": [],
   "source": [
    "def get_selected_text(text, start_idx, end_idx, offsets):\n",
    "    selected_text = \"\"\n",
    "    for ix in range(start_idx, end_idx + 1):\n",
    "        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n",
    "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
    "            selected_text += \" \"\n",
    "    return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLu857dExSgF"
   },
   "outputs": [],
   "source": [
    "def get_tokens(text, offsets):\n",
    "  tokens = []\n",
    "  for i in range(len(offsets)):\n",
    "    s = get_selected_text(text, i, i, offsets)\n",
    "    tokens.append(s)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEUBswZLwIun"
   },
   "outputs": [],
   "source": [
    "def plot_logits(text, start_scores, end_scores, offsets):\n",
    "  tokens = get_tokens(text, offsets)\n",
    "  # Use plot styling from seaborn.\n",
    "  sns.set(style='darkgrid')\n",
    "\n",
    "  # Increase the plot size and font size.\n",
    "  #sns.set(font_scale=1.5)\n",
    "  plt.rcParams[\"figure.figsize\"] = (16,8)\n",
    "\n",
    "  # Pull the scores out of PyTorch Tensors and convert them to 1D numpy arrays.\n",
    "  s_scores = start_scores.flatten()\n",
    "  e_scores = end_scores.flatten()\n",
    "\n",
    "  # We'll use the tokens as the x-axis labels. In order to do that, they all need\n",
    "  # to be unique, so we'll add the token index to the end of each one.\n",
    "  token_labels = []\n",
    "  for (i, token) in enumerate(tokens):\n",
    "      token_labels.append('{:} - {:>2}'.format(token, i))\n",
    "\n",
    "  # Store the tokens and scores in a DataFrame. \n",
    "  # Each token will have two rows, one for its start score and one for its end\n",
    "  # score. The \"marker\" column will differentiate them. A little wacky, I know.\n",
    "  scores = []\n",
    "  for (i, token_label) in enumerate(token_labels):\n",
    "\n",
    "      # Add the token's start score as one row.\n",
    "      scores.append({'token_label': token_label, \n",
    "                    'score': s_scores[i],\n",
    "                    'marker': 'start'})\n",
    "      \n",
    "      # Add  the token's end score as another row.\n",
    "      scores.append({'token_label': token_label, \n",
    "                    'score': e_scores[i],\n",
    "                    'marker': 'end'})\n",
    "      \n",
    "  df = pd.DataFrame(scores)\n",
    "\n",
    "  # Draw a grouped barplot to show start and end scores for each word.\n",
    "  # The \"hue\" parameter is where we tell it which datapoints belong to which\n",
    "  # of the two series.\n",
    "  g = sns.catplot(x=\"token_label\", y=\"score\", hue=\"marker\", data=df,\n",
    "                  kind=\"bar\", height=6, aspect=4)\n",
    "\n",
    "  # Turn the xlabels vertical.\n",
    "  g.set_xticklabels(g.ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "\n",
    "  # Turn on the vertical grid to help align words to scores.\n",
    "  g.ax.grid(True)\n",
    "\n",
    "  #plt.title('Start Word Scores')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFuyfb2_rkm6"
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def compute_jaccard_score(text, start_idx, end_idx, start_logits, end_logits, offsets):\n",
    "    true = get_selected_text(text, start_idx, end_idx, offsets)\n",
    "    \n",
    "    start_pred = np.argmax(start_logits)\n",
    "    end_pred = np.argmax(end_logits)\n",
    "    if start_pred > end_pred:\n",
    "      #1 baseline\n",
    "#         pred = text\n",
    "#         case = 'kir01'\n",
    "      #2 kir\n",
    "        # len_tweet = len(end_logits) - 1\n",
    "        # if start_pred == len_tweet:\n",
    "        # #[01234]\n",
    "        # #[  e s]\n",
    "        #     pred = get_selected_text(text, end_pred, len_tweet, offsets)\n",
    "        #     case = 'kir21'\n",
    "        # else:\n",
    "        # #[01234]\n",
    "        # #[  es ]\n",
    "        #     pred = get_selected_text(text, start_pred, len_tweet, offsets)\n",
    "        #     case = 'kir22'\n",
    "      #3 McCormick\n",
    "        sum_start_end = []\n",
    "        idx_start_end = []\n",
    "        for i, start_value in enumerate(start_logits):\n",
    "            for g, end_value in enumerate(end_logits):\n",
    "                if i > g: # начало забегает за конец\n",
    "                    continue\n",
    "                sum_start_end.append(start_value + end_value)\n",
    "                idx_start_end.append([i,g])\n",
    "        best_position = np.argmax(sum_start_end)\n",
    "        start_pred, end_pred = idx_start_end[best_position]\n",
    "        pred = get_selected_text(text, start_pred, end_pred, offsets)\n",
    "      #DAMP\n",
    "          #print(text)\n",
    "          #print(pred)\n",
    "          #print(true)\n",
    "    else:\n",
    "        pred = get_selected_text(text, start_pred, end_pred, offsets)\n",
    "        #case = 'kir02'\n",
    "\n",
    "    return jaccard(true, pred), true, pred, case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjPG4NLorknB"
   },
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8s-yvC6rknC"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename, threshold):\n",
    "    model.to(device)\n",
    "    \n",
    "    jacs_dict = collections.defaultdict(list)\n",
    "    for epoch in range(num_epochs):       \n",
    "        for phase in ['train', 'val']:\n",
    "            cases = {}\n",
    "            start_time = time.time()\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_jaccard = 0.0\n",
    "            \n",
    "            last_print_time = 0\n",
    "\n",
    "            for x, data in enumerate(dataloaders_dict[phase]):\n",
    "                tokenizer = dataloaders_dict[phase].dataset.tokenizer\n",
    "                if time.time() - last_print_time > 10:\n",
    "                    last_print_time = time.time()\n",
    "                    print(x, end=' ')\n",
    "                ids = data['ids'].to(device)\n",
    "                masks = data['masks'].to(device)\n",
    "                tweet = data['tweet']\n",
    "                offsets = data['offsets'].numpy()\n",
    "                start_idx = data['start_idx'].to(device)\n",
    "                end_idx = data['end_idx'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    start_logits, end_logits = model(ids, masks)\n",
    "\n",
    "                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #xm.optimizer_step(optimizer, barrier=True)\n",
    "                        \n",
    "                    epoch_loss += loss.item() * len(ids)\n",
    "                    \n",
    "                    start_idx = start_idx.cpu().detach().numpy()\n",
    "                    end_idx = end_idx.cpu().detach().numpy()\n",
    "                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n",
    "                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n",
    "                    \n",
    "                    for i in range(len(ids)):                        \n",
    "                        jaccard_score, true, pred, case = compute_jaccard_score(\n",
    "                            tweet[i],\n",
    "                            start_idx[i],\n",
    "                            end_idx[i],\n",
    "                            start_logits[i], \n",
    "                            end_logits[i], \n",
    "                            offsets[i])\n",
    "                        epoch_jaccard += jaccard_score\n",
    "                        if case in cases:\n",
    "                            cases[case] += 1\n",
    "                        else:\n",
    "                            cases[case] = 1\n",
    "                        if phase == 'val' and jaccard_score < threshold:\n",
    "                            ps('\\n',jaccard_score, tweet[i], '\\nTrue:', true,'\\nPred:', pred, '\\nSentiment:', tokenizer.decode([ids[i][1]]))\n",
    "                            plot_logits(tweet[i], start_logits[i], end_logits[i], offsets[i])\n",
    "            ps('')\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            ps('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f} | elapsed sec: {:.1f} | Cases: {}'.format(\n",
    "                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard, time.time() - start_time, \n",
    "                str(cases)))\n",
    "            \n",
    "            jacs_dict[phase].append(epoch_jaccard)\n",
    "            \n",
    "        plt.plot(jacs_dict['train'], '-co', label = 'train')\n",
    "        plt.plot(jacs_dict['val'], '-yv', label = 'val')\n",
    "        plt.ylim((0.5,1.0))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "            \n",
    "    #torch.save(model.state_dict(), filename)\n",
    "        if epoch > 0:\n",
    "            filename = f'{MODELS}e{epoch+1}/roberta_fold{fold}.pth'\n",
    "            torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4QA1qiKrknG"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT1JHuvarknG"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "n_splits = 10\n",
    "threshold = -1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "IS_FAST_CHECK = False\n",
    "FAST_CHECK_RATIO = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JuhFUYfrknK",
    "outputId": "c074a337-099f-4e96-857a-dd8348494d68"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not IS_MISS_TRAIN:\n",
    "    ps(\"num_epochs:\",num_epochs) \n",
    "    ps(\"batch_size:\",batch_size)\n",
    "    ps(\"n_splits:\",n_splits)\n",
    "    ps(\"threshold:\",threshold)\n",
    "\n",
    "    train_df = pd.read_csv(TRAIN)\n",
    "    if IS_FAST_CHECK:\n",
    "        ps('Fast check mode. Reduce train_df size. Old shape: ', train_df.shape)\n",
    "        train_df = train_df.iloc[:int(train_df.shape[0] * FAST_CHECK_RATIO), :]\n",
    "        ps('.. new shape: ', train_df.shape)\n",
    "\n",
    "    train_df['text'] = train_df['text'].astype(str)\n",
    "    train_df['selected_text'] = train_df['selected_text'].astype(str)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df.sentiment), start=1): \n",
    "        ps(f'Fold: {fold}, Batches in train: {len(train_idx)//batch_size}, Batches in val: {len(val_idx)//batch_size}')\n",
    "\n",
    "        model = TweetModel()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
    "        criterion = loss_fn\n",
    "        dataloaders_dict = get_train_val_loaders(train_df, train_idx, val_idx, batch_size)\n",
    "\n",
    "        train_model(\n",
    "            model, \n",
    "            dataloaders_dict,\n",
    "            criterion, \n",
    "            optimizer, \n",
    "            num_epochs,\n",
    "            MODELS + f'roberta_fold{fold}.pth',\n",
    "            threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HOchKCHt3oJ"
   },
   "outputs": [],
   "source": [
    "#!cp '{MODELS}e3/roberta_fold10.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e4/roberta_fold9.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e4/roberta_fold8.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e4/roberta_fold7.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e4/roberta_fold6.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e2/roberta_fold5.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e2/roberta_fold4.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e2/roberta_fold3.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e5/roberta_fold2.pth' '{MODELS}e_best/'\n",
    "#!cp '{MODELS}e4/roberta_fold1.pth' '{MODELS}e_best/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mLd35QOBL8Y",
    "outputId": "182b0362-fe89-44f5-b8d2-3891f05f739f"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bgFl57azcID"
   },
   "source": [
    "# Model Archiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-77zRZbc09GX"
   },
   "outputs": [],
   "source": [
    "##unzip models\n",
    "#OUTPUT = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/output/2020-06-11T234912/'\n",
    "#ARCHIVE_FILE = OUTPUT + 'models.zip'\n",
    "#MODELS = '/content/models/'\n",
    "#!unzip '{ARCHIVE_FILE}' -d '{MODELS}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-Tusj6hPAAk",
    "outputId": "9d6e026f-24a6-4800-b9f6-3c5cf8416295"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if COLAB_USE:\n",
    "##zip models with delete files after creating archive\n",
    "    #OUTPUT = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/output/2020-06-11T234912/'\n",
    "    #ARCHIVE_FILE = OUTPUT + 'models_2.zip'\n",
    "    #MODELS = '/content/drive/My Drive/Colab Notebooks/2020-05_kaggle/output/2020-06-11T234912/models_1/'\n",
    "    #MODELS = '/content/models/models_2/'\n",
    "    !zip -1 -r -j '{ARCHIVE_FILE}' '{MODELS}e4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3e1tFeR4T97X",
    "outputId": "11659727-a673-432b-d327-021078e219f0"
   },
   "outputs": [],
   "source": [
    "if COLAB_USE:\n",
    "    last_print_time = 0\n",
    "    while True:\n",
    "        if time.time() - last_print_time > 300:\n",
    "            last_print_time = time.time()\n",
    "            print(datetime.now(tz=pytz.timezone(\"Europe/Moscow\")).strftime(\"%Y-%m-%dT%H%M%S\"), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p40Rqd2crknN"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uwa2-qjTrknN"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST)\n",
    "test_df['text'] = test_df['text'].astype(str)\n",
    "test_loader = get_test_loader(test_df)\n",
    "predictions = []\n",
    "models = []\n",
    "#for fold in range(skf.n_splits):\n",
    "for fold in (0,1,2,3,5,6,7,8,9):\n",
    "    model = TweetModel()\n",
    "    model.to(device) \n",
    "    model.load_state_dict(torch.load(MODELS + f'roberta_fold{fold+1}.pth'))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "for x, data in enumerate(test_loader):\n",
    "    print(x, end=' ')\n",
    "    ids = data['ids'].to(device)\n",
    "    masks = data['masks'].to(device)\n",
    "    tweet = data['tweet']\n",
    "    offsets = data['offsets'].numpy()\n",
    "\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for model in models:\n",
    "        with torch.no_grad():\n",
    "            output = model(ids, masks)\n",
    "            start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n",
    "            end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n",
    "\n",
    "    start_logits = np.mean(start_logits, axis=0)\n",
    "    end_logits = np.mean(end_logits, axis=0)\n",
    "    for i in range(len(ids)):    \n",
    "        start_pred = np.argmax(start_logits[i])\n",
    "        end_pred = np.argmax(end_logits[i])\n",
    "        if start_pred > end_pred:\n",
    "        #1 baseline\n",
    "            #pred = tweet[i]\n",
    "        #3 McCormick\n",
    "            sum_start_end = []\n",
    "            idx_start_end = []\n",
    "            for k, start_value in enumerate(start_logits[i]):\n",
    "                for g, end_value in enumerate(end_logits[i]):\n",
    "                    if k > g:\n",
    "                        continue\n",
    "                    sum_start_end.append(start_value + end_value)\n",
    "                    idx_start_end.append([k,g])\n",
    "            best_position = np.argmax(sum_start_end)\n",
    "            start_pred, end_pred = idx_start_end[best_position]\n",
    "            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n",
    "        else:\n",
    "            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xlud9UBrknR"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIWSylqorknS"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(SAMPLE_SUBM)\n",
    "sub_df['selected_text'] = predictions\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
    "sub_df.to_csv(os.path.join(OUTPUT, 'submission.csv'), index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
